{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Declare imports and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "INPUT_DIR = \"input\"\n",
    "INPUT_DIR_EVVET = os.path.join(INPUT_DIR, 'evvet')\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "OUTPUT_EVVET_FILE = os.path.join(OUTPUT_DIR, 'evvet_master.csv')\n",
    "\n",
    "OUTPUT_EVVET_META = os.path.join(OUTPUT_DIR, \"evvet_meta.json\")\n",
    "\n",
    "OUTPUT_VEDDRA_FILE = os.path.join(OUTPUT_DIR, 'veddra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create veddra lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Eye disorders', 'Iris, ciliary body and choroid disorders')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "veddra = pd.read_csv(OUTPUT_VEDDRA_FILE)\n",
    "\n",
    "# Create a dictionary for O(1) lookup\n",
    "veddra_lookup = {}\n",
    "\n",
    "# Populate the dictionary with PT and LLT as keys\n",
    "for _, row in veddra.iterrows():\n",
    "    pt = row['Current Preferred Term (PT)']\n",
    "    llt = row['Current Low Level Term (LLT)']\n",
    "    soc = row['Current System Organ Class (SOC) Term']\n",
    "    hlt = row['Current High Level Term (HLT)']\n",
    "    \n",
    "    # Add PT to the dictionary\n",
    "    veddra_lookup[pt] = (soc, hlt)\n",
    "    \n",
    "    # Add LLT to the dictionary\n",
    "    veddra_lookup[llt] = (soc, hlt)\n",
    "\n",
    "display(veddra_lookup['Uveitis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate all output files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run:\n",
      "July 21, 2024 20:33:14 PDT\n",
      "\n",
      "Processing file: 2021.csv...\n",
      "Number of rows: 383\n",
      "\n",
      "Processing file: 2023.csv...\n",
      "Number of rows: 5123\n",
      "\n",
      "Processing file: 2022.csv...\n",
      "Number of rows: 3170\n",
      "\n",
      "Processing file: 2024.csv...\n",
      "Number of rows: 9218\n",
      "\n",
      "Master file compiled and written to archive and source.\n",
      "\n",
      "Total cases: 17894\n",
      "Animals affected: 18749\n",
      "Animals treated: 21701.0\n",
      "Animals died: 2067.0\n",
      "\n",
      "output/evvet_meta.json updated!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "def generate():\n",
    "    # Define the PDT timezone\n",
    "    pdt = pytz.timezone('America/Los_Angeles')\n",
    "    \n",
    "    # Get the current date and time in UTC and convert to PDT\n",
    "    current_datetime = datetime.datetime.now(pytz.utc).astimezone(pdt)\n",
    "    last_updated = current_datetime.strftime(\"%B %d, %Y %H:%M:%S %Z\")\n",
    "    print(f\"Last run:\\n{last_updated}\")\n",
    "\n",
    "    file_pattern = '.csv'\n",
    "\n",
    "    # Delete the output file if it exists\n",
    "    if os.path.exists(OUTPUT_EVVET_FILE):\n",
    "        os.remove(OUTPUT_EVVET_FILE)\n",
    "\n",
    "    # List all CSV files in the input directory\n",
    "    csv_files = [f for f in os.listdir(INPUT_DIR_EVVET) if f.endswith(file_pattern)]\n",
    "    \n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(INPUT_DIR_EVVET, file))\n",
    "        df.dropna(how='all', inplace=True)\n",
    "        print(f\"\\nProcessing file: {file}...\")\n",
    "        print(f\"Number of rows: {len(df)}\")\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into one\n",
    "    master_df = pd.concat(df_list, ignore_index=True)\n",
    "    master_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Reorder columns to move 'AER form' to the last index if it exists in the dataframe\n",
    "    if 'AER form' in master_df.columns:\n",
    "        cols = master_df.columns.tolist()\n",
    "        cols.append(cols.pop(cols.index('AER form')))\n",
    "        master_df = master_df[cols]\n",
    "\n",
    "    # Move 'Drug' column to the end if it exists in the dataframe\n",
    "    if 'Drug' in master_df.columns:\n",
    "        cols = master_df.columns.tolist()\n",
    "        cols.append(cols.pop(cols.index('Drug')))\n",
    "        master_df = master_df[cols]\n",
    "\n",
    "    # Move 'Received date' column to the first index if it exists in the dataframe\n",
    "    if 'Received date' in master_df.columns:\n",
    "        cols = master_df.columns.tolist()\n",
    "        cols.insert(0, cols.pop(cols.index('Received date')))\n",
    "        master_df = master_df[cols]\n",
    "\n",
    "    # Sort the dataframe by 'Received date'\n",
    "    master_df.sort_values(by='Received date', inplace=True)\n",
    "\n",
    "    # Drop any empty rows in master_df\n",
    "    master_df.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Change Received Date column's format\n",
    "    master_df['Received date'] = pd.to_datetime(master_df['Received date'])\n",
    "\n",
    "    # Check for any rows where dates couldn't be parsed\n",
    "    if master_df['Received date'].isna().any():\n",
    "        print(\"Some dates couldn't be parsed and were set to NaT\")\n",
    "\n",
    "    #####\n",
    "    # Add VeDDRA SOC and HLT columns to the evvet DataFrame\n",
    "    #####\n",
    "    # Initialize the columns\n",
    "    master_df['VeDDRA SOC'] = ''\n",
    "    master_df['VeDDRA HLT'] = ''\n",
    "\n",
    "    # Iterate through each row in evvet DataFrame\n",
    "    for index, row in master_df.iterrows():\n",
    "        # print(row['Reaction'])\n",
    "        reactions = row['Reaction'].split(',')\n",
    "        soc_matches = set()\n",
    "        hlt_matches = set()\n",
    "        for reaction in reactions:\n",
    "            reaction = reaction.strip()\n",
    "            if reaction in veddra_lookup:\n",
    "                soc, hlt = veddra_lookup[reaction]\n",
    "                soc_matches.add(soc)\n",
    "                hlt_matches.add(hlt)\n",
    "        \n",
    "        # print(soc_matches)\n",
    "        # print(hlt_matches)\n",
    "        # print()\n",
    "\n",
    "        # Update the VeDDRA SOC and VeDDRA HLT columns with the matches\n",
    "        if soc_matches:\n",
    "            master_df.at[index, 'VeDDRA SOC'] = '; '.join(sorted(soc_matches))\n",
    "        if hlt_matches:\n",
    "            master_df.at[index, 'VeDDRA HLT'] = '; '.join(sorted(hlt_matches))\n",
    "\n",
    "    # Remove the columns from their current positions\n",
    "    veddra_soc = master_df.pop('VeDDRA SOC')\n",
    "    veddra_hlt = master_df.pop('VeDDRA HLT')\n",
    "    # Insert the columns at the desired positions\n",
    "    master_df.insert(11, 'VeDDRA SOC', veddra_soc)\n",
    "    master_df.insert(12, 'VeDDRA HLT', veddra_hlt)\n",
    "\n",
    "    # Load the most recent CSV listed in the meta file\n",
    "    with open(OUTPUT_EVVET_META, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    \n",
    "    if meta['csvs']:\n",
    "        last_csv_info = meta['csvs'][0]\n",
    "        last_master_df = pd.read_csv(os.path.join(OUTPUT_DIR, last_csv_info['name']), index_col='Received date', parse_dates=True)\n",
    "        \n",
    "        # Set the index to 'Received date' for master_df\n",
    "        master_df.set_index('Received date', inplace=True)\n",
    "\n",
    "        # Check if the dataframes are identical\n",
    "        if master_df.equals(last_master_df):\n",
    "            print()\n",
    "            print(\"Duplicate fetch. Aborted!\")\n",
    "            return float('nan')\n",
    "\n",
    "    # Write the updated master dataframe to a new CSV\n",
    "    new_csv_name = f\"evvet_master_{current_datetime.strftime('%Y%m%d')}.csv\"\n",
    "    # Write to csv archive\n",
    "    master_df.to_csv(os.path.join(OUTPUT_DIR, new_csv_name))\n",
    "    # Make this the new master file (copy)\n",
    "    master_df.to_csv(OUTPUT_EVVET_FILE)\n",
    "    \n",
    "    print(\"\\nMaster file compiled and written to archive and source.\")\n",
    "\n",
    "    print()\n",
    "    print(f\"Total cases: {len(master_df)}\")\n",
    "    print(f\"Animals affected: {master_df['Animals affected'].sum()}\")\n",
    "    print(f\"Animals treated: {master_df['Animals treated'].sum()}\")\n",
    "    print(f\"Animals died: {master_df['Animals died'].sum()}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Update the meta file\n",
    "    new_csv_info = {\n",
    "        \"id\": last_csv_info['id'] + 1 if meta['csvs'] else 1,\n",
    "        \"name\": new_csv_name,\n",
    "        \"timestamp\": current_datetime.isoformat()\n",
    "    }\n",
    "    meta['csvs'].insert(0, new_csv_info)\n",
    "    \n",
    "    with open(OUTPUT_EVVET_META, \"w\") as f:\n",
    "        json.dump(meta, f, indent=4)\n",
    "    print(f'{OUTPUT_EVVET_META} updated!')\n",
    "\n",
    "    return master_df\n",
    "\n",
    "evvet = generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
